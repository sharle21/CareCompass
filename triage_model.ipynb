{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOiOMiUtAKAO7Q1NKj0O+xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4359052622da4dfcb79c048aee6822f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504930fdb98e43b2902d98dceafe58c8",
              "IPY_MODEL_c898904b0109404499d62ff1bec20e66",
              "IPY_MODEL_ea51881244934652bd133bcae446d22b"
            ],
            "layout": "IPY_MODEL_488149d502f64e5cac5778b9ec83a4e2"
          }
        },
        "504930fdb98e43b2902d98dceafe58c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd3fa4162a35413c9a4c8a17cc2e7928",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5602b322ee1473cab5d38f818169182",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "c898904b0109404499d62ff1bec20e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24806ac1ab73497c889b11c7b32a0fda",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5049a5bae8fd4903927d16a856de0d7a",
            "value": 11
          }
        },
        "ea51881244934652bd133bcae446d22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a478806bfd834ba5abde1c82d62954f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9dfebac1f24b4afcafe0be5dbd96d52c",
            "value": "â€‡11/11â€‡[00:00&lt;00:00,â€‡10.72it/s]"
          }
        },
        "488149d502f64e5cac5778b9ec83a4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3fa4162a35413c9a4c8a17cc2e7928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5602b322ee1473cab5d38f818169182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24806ac1ab73497c889b11c7b32a0fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5049a5bae8fd4903927d16a856de0d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a478806bfd834ba5abde1c82d62954f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dfebac1f24b4afcafe0be5dbd96d52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharle21/In-Network-Care-Navigator/blob/anagha_dev/triage_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CELL 1: SETUP AND LOGINS ---\n",
        "# This cell installs all libraries and securely logs you in.\n",
        "\n",
        "!pip install \"transformers[torch]\" fastapi uvicorn pyngrok nest-asyncio -q\n",
        "\n",
        "from huggingface_hub import login\n",
        "from pyngrok import conf\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # 1. Get HF_TOKEN from Colab Secrets and log in\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"âœ… Successfully logged into Hugging Face!\")\n",
        "\n",
        "    # 2. Get NGROK_TOKEN from Colab Secrets and configure ngrok\n",
        "    NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
        "    conf.get_default().auth_token = NGROK_TOKEN\n",
        "    print(\"âœ… Successfully configured ngrok!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"ðŸš¨ Error loading secrets.\")\n",
        "    print(\"Did you add 'HF_TOKEN' and 'NGROK_TOKEN' to your Colab Secrets (the 'key' icon)?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCxih3nOFzJ8",
        "outputId": "28be3793-8c2c-4388-c11f-258a78fdbd6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Successfully logged into Hugging Face!\n",
            "âœ… Successfully configured ngrok!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668,
          "referenced_widgets": [
            "4359052622da4dfcb79c048aee6822f4",
            "504930fdb98e43b2902d98dceafe58c8",
            "c898904b0109404499d62ff1bec20e66",
            "ea51881244934652bd133bcae446d22b",
            "488149d502f64e5cac5778b9ec83a4e2",
            "cd3fa4162a35413c9a4c8a17cc2e7928",
            "c5602b322ee1473cab5d38f818169182",
            "24806ac1ab73497c889b11c7b32a0fda",
            "5049a5bae8fd4903927d16a856de0d7a",
            "a478806bfd834ba5abde1c82d62954f0",
            "9dfebac1f24b4afcafe0be5dbd96d52c"
          ]
        },
        "id": "otWa0ZjiAvXJ",
        "outputId": "77b2e10a-0a17-4099-8c47-c64d94be6287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MedGemma Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4359052622da4dfcb79c048aee6822f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedGemma Model Loaded.\n",
            "Starting Uvicorn server in a background thread...\n",
            "Waiting 10 seconds for the server to boot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [935]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "--- Your Triage API is LIVE at: NgrokTunnel: \"https://unfoldable-nonfeeble-arlo.ngrok-free.dev\" -> \"http://localhost:8000\" ---\n",
            "--- Give this URL to Person C! ---\n",
            "------------------------------------------------------------\n",
            "The API is live. This Colab cell must remain running.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-11-02T20:45:17+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-c9191d3a-bca6-4281-bffe-5063f0650fef acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-287959595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Keep the main thread alive (this will block forever, which is correct)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mserver_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# --- CELL 2: YOUR MAIN APPLICATION ---\n",
        "\n",
        "# --- 1. IMPORTS ---\n",
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import uvicorn\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok\n",
        "# (No need to import 'conf' or 'userdata' here)\n",
        "\n",
        "# --- 2. LOAD THE MEDGEMMA MODEL ---\n",
        "print(\"Loading MedGemma Model...\")\n",
        "model_id = \"google/medgemma-27b-text-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\", # This tells it to use the Colab GPU\n",
        ")\n",
        "print(\"MedGemma Model Loaded.\")\n",
        "\n",
        "# --- 3. CREATE YOUR TRIAGE LOGIC FUNCTION ---\n",
        "def get_triage_from_text(raw_text: str):\n",
        "    \"\"\"\n",
        "    Runs the MedGemma model and forces it to output a triage level.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a medical triage assistant. A user has provided their symptoms.\n",
        "    Classify the severity into one of four levels: ER, Urgent Care, Consultation, or Self-Care.\n",
        "    User Symptoms: \"{raw_text}\"\n",
        "    Respond with *only* the single triage level string.\n",
        "    Triage Level:\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(input_ids, max_new_tokens=10)\n",
        "    response_text = tokenizer.decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "    if \"ER\" in response_text:\n",
        "        return \"ER\"\n",
        "    elif \"Urgent Care\" in response_text:\n",
        "        return \"Urgent Care\"\n",
        "    elif \"Consultation\" in response_text:\n",
        "        return \"Consultation\"\n",
        "    else:\n",
        "        return \"Self-Care\"\n",
        "\n",
        "# --- 4. CREATE THE API ---\n",
        "app = FastAPI()\n",
        "\n",
        "class TriageRequest(BaseModel):\n",
        "    symptoms: str\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"status\": \"Triage Model API is running\"}\n",
        "\n",
        "@app.post(\"/triage\")\n",
        "def run_triage(request: TriageRequest):\n",
        "    triage_level = get_triage_from_text(request.symptoms)\n",
        "    return {\n",
        "        \"predicted_disease\": \"N/A (Triage by MedGemma)\",\n",
        "        \"triage_level\": triage_level\n",
        "    }\n",
        "\n",
        "# --- 5. START THE SERVER AND CREATE THE PUBLIC URL ---\n",
        "# We need to import threading and time\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# We must run the uvicorn server in a separate thread\n",
        "# so it doesn't block the main thread or conflict with Colab's event loop.\n",
        "\n",
        "def run_server():\n",
        "    # This is a blocking call, so it's perfect for a thread\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "print(\"Starting Uvicorn server in a background thread...\")\n",
        "server_thread = threading.Thread(target=run_server)\n",
        "server_thread.start()\n",
        "\n",
        "# Give the server 10 seconds to fully start up.\n",
        "# This is important!\n",
        "print(\"Waiting 10 seconds for the server to boot...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Now that the server is running, connect ngrok to it.\n",
        "try:\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(\"---\" * 20)\n",
        "    print(f\"--- Your Triage API is LIVE at: {public_url} ---\")\n",
        "    print(\"--- Give this URL to Person C! ---\")\n",
        "    print(\"---\" * 20)\n",
        "    print(\"The API is live. This Colab cell must remain running.\")\n",
        "\n",
        "    # Keep the main thread alive (this will block forever, which is correct)\n",
        "    server_thread.join()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ðŸš¨ Error starting ngrok: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAoIarvkPkke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}